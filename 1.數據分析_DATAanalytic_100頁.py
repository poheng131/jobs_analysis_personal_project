# -*- coding: utf-8 -*-
"""
Created on Tue Jun 17 13:07:35 2025

@author: student
"""

import requests
import time
import pandas as pd
from datetime import datetime
from urllib.parse import quote

# ğŸ” åªæŠ“ç‰¹å®šå…©å€‹é—œéµå­—
KEYWORDS = ["æ•¸æ“šåˆ†æ", "Data Analytic"]

# âŒ æ’é™¤ä¸ç›¸é—œè·ç¼ºï¼ˆæ ¹æ“šè·ç¼ºåç¨±ï¼‰
EXCLUDE_WORDS = ["åŠ©ç†", "å®¢æœ", "é–€å¸‚", "å„²å‚™å¹¹éƒ¨", "å·¥è®€", "è¬›å¸«", "ä½œæ¥­å“¡", "è¡Œæ”¿", "æ¥­å‹™", "å¤–åŒ…", "è¨­è¨ˆ"]

def is_relevant_job(title):
    if any(bad in title for bad in EXCLUDE_WORDS):
        return False
    return True

# âœ… ä¸»çˆ¬èŸ²å‡½å¼ï¼ˆä¿ç•™æ‰€æœ‰æ¬„ä½ï¼‰
def get_104_jobs_raw(keyword, max_pages=100):
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Referer": "https://www.104.com.tw/jobs/search/",
    }
    jobs = []
    page = 1
    page_size = 20

    while page <= max_pages:
        url = (
            "https://www.104.com.tw/jobs/search/list?"
            f"ro=0&kwop=7&keyword={quote(keyword)}&order=11&asc=0&page={page}&mode=s&jobsource=2018indexpoc"
        )

        print(f"ğŸ” æŠ“å–ã€Œ{keyword}ã€ç¬¬ {page} é ")
        resp = requests.get(url, headers=headers)
        try:
            data = resp.json()
        except Exception:
            print("âš ï¸ ç„¡æ³•è§£æ JSONï¼Œè·³é")
            break

        if "data" not in data or "list" not in data["data"]:
            print("âš ï¸ è³‡æ–™æ ¼å¼éŒ¯èª¤ï¼ŒçµæŸ")
            break

        job_list = data["data"]["list"]
        if not job_list:
            print("âœ… ç„¡æ›´å¤šè·ç¼º")
            break

        today = datetime.today().strftime("%Y-%m-%d")
        for job in job_list:
            title = job.get("jobName", "")
            if is_relevant_job(title):
                job["çˆ¬èŸ²æ—¥æœŸ"] = today
                jobs.append(job)

        print(f"âœ… ç¬¬ {page} é å®Œæˆï¼Œå…±ç´¯ç© {len(jobs)} ç­†")
        page += 1
        time.sleep(1)

    return jobs

# âœ… ä¸»æµç¨‹
if __name__ == "__main__":
    all_jobs = []
    for kw in KEYWORDS:
        jobs = get_104_jobs_raw(kw, max_pages=100)
        all_jobs.extend(jobs)

    df = pd.DataFrame(all_jobs)
    
    # åˆ†é¡å‡½å¼
    def classify_job(title):
        title = str(title).lower()
    
        core_keywords = [
            'data analyst', 'è³‡æ–™åˆ†æ', 'æ•¸æ“šåˆ†æ', 'data analysis', 
            'biå·¥ç¨‹å¸«', 'bi analyst', 'business intelligence', 'å•†æ¥­åˆ†æ'
        ]
    
        applied_keywords = [
            'è¡ŒéŠ·åˆ†æ', 'ç‡Ÿé‹åˆ†æ', 'crmåˆ†æ', 'ç”¢å“åˆ†æ', 'é›»å•†åˆ†æ',
            'marketing analyst', 'operation analyst', 'crm', 'insight'
        ]
    
        unrelated_keywords = [
            'åŠ©ç†', 'ç ”ç©¶åŠ©ç†', 'ä¼åŠƒ', 'è¡ŒéŠ·ä¼åŠƒ', 'è¡Œæ”¿', 'å®¢æœ',
            'pm', 'sales', 'æ¥­å‹™', 'driver', 'è¨­è¨ˆ', 'å·¥è®€', 'å¤–åŒ…'
        ]
    
        if any(k in title for k in core_keywords):
            return 'core'
        elif any(k in title for k in applied_keywords):
            return 'applied'
        elif any(k in title for k in unrelated_keywords):
            return 'unrelated'
        else:
            return 'unknown'
    
    # âœ… å¥—ç”¨åˆ†é¡ï¼Œå¢åŠ  job_category æ¬„ä½
    df['job_category'] = df['jobName'].apply(classify_job)

    
    df.drop_duplicates(subset=["jobName", "custName", "jobNo"], inplace=True)

    today = datetime.today().strftime("%Y-%m-%d")
    filename = f"104_jobs_raw_{today}.csv"
    df.to_csv(filename, index=False, encoding="utf-8-sig")

    print(f"\nğŸ‰ å®Œæˆï¼å…±å„²å­˜ {len(df)} ç­†åŸå§‹è·ç¼ºè³‡æ–™ âœ {filename}")

